import os
import google.generativeai as genai
import requests
import config
from google.genai.types import GenerateContentConfig
import json
from dotenv import load_dotenv
import time
import helper_model
load_dotenv()
import canvas_ops
import asyncio
import random
import threading
import httpx



BASE_URL = os.getenv("CANVAS_URL", "https://board-v24problem.vercel.app")
print("#### side_agent.py CANVAS_URL : ",BASE_URL)

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
# MODEL = "gemini-2.5-pro"

MODEL = "gemini-2.5-flash-lite"
# MODEL = "gemini-2.5-flash"
# MODEL = "gemini-2.0-flash-lite"
# MODEL = "gemini-2.0-flash"



def parse_tool(query):
    with open("system_prompts/side_agent_parser.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()

    # Define response schema for your side-agent output
    RESPONSE_SCHEMA = {
        "type": "OBJECT",
        "properties": {
            "query": {
                "type": "STRING",
                "description": "User raw question or command."
            },
            "tool": {
                "type": "STRING",
                "enum": ["navigate_canvas", "generate_task", "get_easl_answer", "general"],
                "description": "Tool category."
            }
        },
        "required": ["query", "tool"]
    }

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )

    prompt = f"User query : '{query}'\n\nPick tool for this query."

    # ‚úÖ IMPORTANT: Use a **dict** not GenerateContentConfig
    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
    )

    result = json.loads(resp.text)
    # print("Result :")
    # print(result)
    return result


def resolve_object_id(query: str, context: str):
    """
    Given:
      - query (str): what user wants (e.g., "open medication timeline")
      - context (list): list of canvas object records [{ objectId, title, content, ... }]

    Returns:
      { "objectId": "<id>" } or { "objectId": null }
    """

    # Load system prompt
    with open("system_prompts/objectid_parser.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()

    # Enforce JSON structure
    RESPONSE_SCHEMA = {
        "type": "OBJECT",
        "properties": {
            "objectId": {
                "type": "STRING",
                "description": "Selected objectId"
            }
        },
        "required": ["objectId"]
    }

    # Prepare request text
    prompt = f"""
User Query:
{query}

Context (Canvas Objects):
{context}

Return ONLY the matching objectId in JSON.
"""

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )

    # Generate with schema enforcement
    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
    )

    result = json.loads(resp.text)

    # Optional logging:
    # print("Resolver Output:", result)

    ### CANVAS ACTION HERE
    focus_res = asyncio.run(canvas_ops.focus_item(result.get("objectId")))
    print(f"  üéØ Navigation completed", focus_res)
    return result

async def trigger_easl(question):
    easl_q = helper_model.generate_question(question)

    easl_todo_payload = {
        "title": "EASL Guideline Query Workflow",
        "description": "Handling query to EASL Guideline Agent in background",
        "todos": [
            {
            "id": "task-101",
            "text": "Creating question query and generating context",
            "status": "executing",
            "agent": "Data Analyst Agent",
            "subTodos": [
                    {
                    "text": f"Base question : {question}",
                    "status": "executing"
                    },
                    {
                    "text": f"Detailed Question is generated by ContextGen Agent : {easl_q}",
                    "status": "executing"
                    }
                ]
            },
            {
            "id": "task-102",
            "text": "Send query to EASL Guideline Agent",
            "status": "pending",
            "agent": "Data Analyst Agent",
            "subTodos": [
                    {
                    "text": f"Query is processing",
                    "status": "pending"
                    },
                    {
                    "text": "Result is created in canvas",
                    "status": "pending"
                    }
                ]
            }
        ]
        }
    
    todo_obj = await canvas_ops.create_todo(easl_todo_payload)
    ### EASL TRIGGER ACTION HERE

    for i in range(2):
        await canvas_ops.update_todo(
            {
                "id" : todo_obj.get('id'),
                "task_id" : "task-101",
                "index":f"{i}",
                "status" : "finished"
            }
        )
        await asyncio.sleep(random.randint(1, 3))

    await canvas_ops.update_todo(
        {
            "id" : todo_obj.get('id'),
            "task_id" : "task-101",
            "index":"",
            "status" : "finished"
        }
    )
    await asyncio.sleep(random.randint(1, 3))
    # context = await canvas_ops.get_agent_context(query)
    await canvas_ops.update_todo(
        {
            "id" : todo_obj.get('id'),
            "task_id" : "task-102",
            "index":"",
            "status" : "executing"
        }
    )
    await asyncio.sleep(random.randint(1, 3))
    easl_status = await canvas_ops.initiate_easl_iframe(easl_q)
    for i in range(2):
        await canvas_ops.update_todo(
            {
                "id" : todo_obj.get('id'),
                "task_id" : "task-102",
                "index":f"{i}",
                "status" : "finished"
            }
        )
        await asyncio.sleep(random.randint(1, 3))
    await canvas_ops.update_todo(
        {
            "id" : todo_obj.get('id'),
            "task_id" : "task-102",
            "index":"",
            "status" : "finished"
        }
    )
    print("iframe status:", easl_status)
    iframe_id = "iframe-item-easl-interface"
    await canvas_ops.focus_item(iframe_id)
    print(f"  ‚úÖ EASL Answer completed")
    return 


async def load_ehr():
    print("Start load_ehr")
    url = BASE_URL + "/api/board-items"
    
    async with httpx.AsyncClient(timeout=10) as client:
        response = await client.get(url)
        data = response.json()

        return data

async def generate_response(todo_obj):
    with open("system_prompts/clinical_agent.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )
    print(f"Running helper model")
    ehr_data = await load_ehr()
    # print("EHR result :", ehr_data)
    prompt = f"""Please execute this todo : 
        {todo_obj}


        This is patient encounter data : {ehr_data}"""

    resp = model.generate_content(prompt)
    with open(f"{config.output_dir}/chatmode_generate_response.md", "w", encoding="utf-8") as f:
        f.write(resp.text)

    print("Agent Result :", resp.text[:200])
    return {
        "answer": resp.text.replace("```markdown", " ").replace("```", "")
        }



def start_background_agent_processing(action_data, todo_obj):
    # Always run background task in its own event loop
    threading.Thread(
        target=lambda: asyncio.run(_handle_agent_processing(action_data, todo_obj)),
        daemon=True
    ).start()

    print("  üîÑ Background processing started (separate event loop)")

async def _handle_agent_processing(action_data, todo_obj):
    """Handle agent processing in background"""
    try:
        print("In _handle_agent_processing")
        # agent_res = await canvas_ops.get_agent_answer(action_data)
        
        data = await generate_response(action_data)

        agent_res = {}
        agent_res['content'] = data.get('answer', '')
        if action_data.get('title'):
            agent_res['title'] = action_data.get('title', '').lower().replace("to do", "Result").capitalize()


        todo_id = todo_obj.get("id")
        for t in todo_obj.get("todoData",{}).get('todos',[]):
            t_id = t.get('id')
            await canvas_ops.update_todo(
                    {
                        "id" : todo_id,
                        "task_id" : t_id,
                        "index":"",
                        "status" : "executing"
                    }
                )
            for i, st in enumerate(t.get('subTodos',[])):
                await canvas_ops.update_todo(
                    {
                        "id" : todo_id,
                        "task_id" : t_id,
                        "index":f"{i}",
                        "status" : "finished"
                    }
                )
                await asyncio.sleep(random.randint(1, 3))
            await canvas_ops.update_todo(
                    {
                        "id" : todo_id,
                        "task_id" : t_id,
                        "index":"",
                        "status" : "finished"
                    }
                )
            await asyncio.sleep(random.randint(2, 3))

        agent_res['zone'] = "raw-ehr-data-zone"
        create_agent_res = await canvas_ops.create_result(agent_res)
        print(f"  ‚úÖ Analysis completed")
        
        
            
    except Exception as e:
        print(f"‚ùå Background processing error: {e}")
        # Send error info to Gemini
        

async def generate_task_workflow(query: str):
    with open("system_prompts/task_generator.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()

    RESPONSE_SCHEMA = {
        "type": "object",
        "properties": {
            "title": {"type": "string"},
            "description": {"type": "string"},
            "todos": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "string"},
                        "text": {"type": "string"},
                        "status": {"type": "string", "enum": ["pending", "executing", "finished"]},
                        "agent": {"type": "string"},
                        "subTodos": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "text": {"type": "string"},
                                    "status": {"type": "string", "enum": ["pending", "executing", "finished"]}
                                },
                                "required": ["text", "status"]
                            }
                        }
                    },
                    "required": ["id", "text", "status", "agent", "subTodos"]
                }
            }
        },
        "required": ["title", "description", "todos"]
    }

    prompt = f"User request:\n{query}\n\nGenerate the task workflow JSON."

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )

    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
    )
    ## Generated todo
    todo_json = json.loads(resp.text)
    with open(f"{config.output_dir}/chatmode_todo_generated.json", "w", encoding="utf-8") as f:
        json.dump(todo_json, f, ensure_ascii=False, indent=4)


    ## Create todo object
    task_res = await canvas_ops.create_todo(todo_json)

    with open(f"{config.output_dir}/chatmode_todo_object_response.json", "w", encoding="utf-8") as f:
        json.dump(task_res, f, ensure_ascii=False, indent=4)

    start_background_agent_processing(todo_json, task_res)

    return task_res

# start_time = time.time()

# query = "Pull radiology data for Sarah Miller"
# parse_tool(query)

# end_time = time.time()
# execution_time = end_time - start_time
# print(f"Execution time: {execution_time:.4f} seconds")