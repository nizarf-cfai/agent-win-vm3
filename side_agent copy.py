import os
import google.generativeai as genai
import requests
import config
from google.genai.types import GenerateContentConfig
import json
from dotenv import load_dotenv
import time
import helper_model
load_dotenv()
import canvas_ops
import asyncio
import random
import threading
import httpx
import config



BASE_URL = os.getenv("CANVAS_URL", "https://board-v24problem.vercel.app")
print("#### side_agent.py CANVAS_URL : ",BASE_URL)

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
# MODEL = "gemini-2.5-pro"

MODEL = "gemini-2.5-flash-lite"
# MODEL = "gemini-2.5-flash"
# MODEL = "gemini-2.0-flash-lite"
# MODEL = "gemini-2.0-flash"



def parse_tool(query):
    with open("system_prompts/side_agent_parser.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()

    # Define response schema for your side-agent output
    RESPONSE_SCHEMA = {
        "type": "OBJECT",
        "properties": {
            "query": {
                "type": "STRING",
                "description": "User raw question or command."
            },
            "tool": {
                "type": "STRING",
                "enum": ["navigate_canvas", "generate_task", "get_easl_answer", "general"],
                "description": "Tool category."
            }
        },
        "required": ["query", "tool"]
    }

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )

    prompt = f"User query : '{query}'\n\nPick tool for this query."

    # ‚úÖ IMPORTANT: Use a **dict** not GenerateContentConfig
    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
    )

    result = json.loads(resp.text)
    # print("Result :")
    # print(result)
    return result


async def resolve_object_id(query: str, context: str):

    # Load system prompt
    with open("system_prompts/objectid_parser.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()

    # Enforce JSON structure
    RESPONSE_SCHEMA = {
        "type": "OBJECT",
        "properties": {
            "objectId": {
                "type": "STRING",
                "description": "Selected objectId"
            }
        },
        "required": ["objectId"]
    }

    # Prepare request text
    prompt = f"""
    User Query:
    {query}

    Context (Canvas Objects):
    {context}

    Return ONLY the matching objectId in JSON.
    """

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )

    # Generate with schema enforcement
    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
    )

    result = json.loads(resp.text)

    # Optional logging:
    # print("Resolver Output:", result)

    ### CANVAS ACTION HERE
    focus_res = await canvas_ops.focus_item(result.get("objectId"))
    print(f"  üéØ Navigation completed", focus_res)
    return result

async def trigger_easl(question):
    easl_q = await helper_model.generate_question(question)

    easl_todo_payload = {
        "title": "EASL Guideline Query Workflow",
        "description": "Handling query to EASL Guideline Agent in background",
        "todos": [
            {
            "id": "task-101",
            "text": "Creating question query and generating context",
            "status": "executing",
            "agent": "Data Analyst Agent",
            "subTodos": [
                    {
                    "text": f"Base question : {question}",
                    "status": "executing"
                    },
                    {
                    "text": f"Detailed Question is generated by ContextGen Agent : {easl_q}",
                    "status": "executing"
                    }
                ]
            },
            {
            "id": "task-102",
            "text": "Send query to EASL Guideline Agent",
            "status": "pending",
            "agent": "Data Analyst Agent",
            "subTodos": [
                    {
                    "text": f"Query is processing",
                    "status": "pending"
                    },
                    {
                    "text": "Result is created in canvas",
                    "status": "pending"
                    }
                ]
            }
        ]
        }
    
    todo_obj = await canvas_ops.create_todo(easl_todo_payload)
    ### EASL TRIGGER ACTION HERE

    for i in range(2):
        await canvas_ops.update_todo(
            {
                "id" : todo_obj.get('id'),
                "task_id" : "task-101",
                "index":f"{i}",
                "status" : "finished"
            }
        )
        await asyncio.sleep(random.randint(1, 3))

    await canvas_ops.update_todo(
        {
            "id" : todo_obj.get('id'),
            "task_id" : "task-101",
            "index":"",
            "status" : "finished"
        }
    )
    await asyncio.sleep(random.randint(1, 3))
    # context = await canvas_ops.get_agent_context(query)
    await canvas_ops.update_todo(
        {
            "id" : todo_obj.get('id'),
            "task_id" : "task-102",
            "index":"",
            "status" : "executing"
        }
    )
    await asyncio.sleep(random.randint(1, 3))
    easl_status = await canvas_ops.initiate_easl_iframe(easl_q)
    for i in range(2):
        await canvas_ops.update_todo(
            {
                "id" : todo_obj.get('id'),
                "task_id" : "task-102",
                "index":f"{i}",
                "status" : "finished"
            }
        )
        await asyncio.sleep(random.randint(1, 3))
    await canvas_ops.update_todo(
        {
            "id" : todo_obj.get('id'),
            "task_id" : "task-102",
            "index":"",
            "status" : "finished"
        }
    )
    print("iframe status:", easl_status)
    iframe_id = "iframe-item-easl-interface"
    await canvas_ops.focus_item(iframe_id)
    print(f"  ‚úÖ EASL Answer completed")
    return 


async def load_ehr():
    print("Start load_ehr")
    url = BASE_URL + "/api/board-items"
    
    async with httpx.AsyncClient(timeout=10) as client:
        response = await client.get(url)
        data = response.json()

        return data

async def generate_response(todo_obj):
    with open("system_prompts/clinical_agent.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )
    print(f"Running helper model")
    ehr_data = await load_ehr()
    # print("EHR result :", ehr_data)
    prompt = f"""Please generate result for this todo : 
        {todo_obj}


        This is patient raw data : {ehr_data}"""

    resp = model.generate_content(prompt)
    with open(f"{config.output_dir}/chatmode_generate_response.md", "w", encoding="utf-8") as f:
        f.write(resp.text)

    print("Agent Result :", resp.text[:200])
    return {
        "answer": resp.text.replace("```markdown", " ").replace("```", "")
        }



def start_background_agent_processing(action_data, todo_obj):
    # Always run background task in its own event loop
    threading.Thread(
        target=lambda: asyncio.run(_handle_agent_processing(action_data, todo_obj)),
        daemon=True
    ).start()

    print("  üîÑ Background processing started (separate event loop)")

async def _handle_agent_processing(action_data, todo_obj):
    """Handle agent processing in background"""
    try:
        print("In _handle_agent_processing")
        # agent_res = await canvas_ops.get_agent_answer(action_data)
        
        data = await generate_response(action_data)

        agent_res = {}
        agent_res['content'] = data.get('answer', '')
        if action_data.get('title'):
            agent_res['title'] = action_data.get('title', '').lower().replace("to do", "Result").capitalize()


        todo_id = todo_obj.get("id")
        for t in todo_obj.get("todoData",{}).get('todos',[]):
            t_id = t.get('id')
            await canvas_ops.update_todo(
                    {
                        "id" : todo_id,
                        "task_id" : t_id,
                        "index":"",
                        "status" : "executing"
                    }
                )
            for i, st in enumerate(t.get('subTodos',[])):
                await canvas_ops.update_todo(
                    {
                        "id" : todo_id,
                        "task_id" : t_id,
                        "index":f"{i}",
                        "status" : "finished"
                    }
                )
                await asyncio.sleep(random.randint(1, 3))
            await canvas_ops.update_todo(
                    {
                        "id" : todo_id,
                        "task_id" : t_id,
                        "index":"",
                        "status" : "finished"
                    }
                )
            await asyncio.sleep(random.randint(2, 3))

        agent_res['zone'] = "raw-ehr-data-zone"
        create_agent_res = await canvas_ops.create_result(agent_res)
        print(f"  ‚úÖ Analysis completed")
        
        
            
    except Exception as e:
        print(f"‚ùå Background processing error: {e}")
        # Send error info to Gemini
        

async def generate_task_obj(query):
    with open("system_prompts/task_generator.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()

    RESPONSE_SCHEMA = {
        "type": "object",
        "properties": {
            "title": {"type": "string"},
            "description": {"type": "string"},
            "todos": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "string"},
                        "text": {"type": "string"},
                        "status": {"type": "string", "enum": ["pending", "executing", "finished"]},
                        "agent": {"type": "string"},
                        "subTodos": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "text": {"type": "string"},
                                    "status": {"type": "string", "enum": ["pending", "executing", "finished"]}
                                },
                                "required": ["text", "status"]
                            }
                        }
                    },
                    "required": ["id", "text", "status", "agent", "subTodos"]
                }
            }
        },
        "required": ["title", "description", "todos"]
    }

    prompt = f"User request:\n{query}\n\nGenerate the task workflow JSON."

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )

    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
    )
    ## Generated todo
    todo_json = json.loads(resp.text)
    with open(f"{config.output_dir}/chatmode_todo_generated.json", "w", encoding="utf-8") as f:
        json.dump(todo_json, f, ensure_ascii=False, indent=4)
    ## Create todo object
    task_res = await canvas_ops.create_todo(todo_json)

    with open(f"{config.output_dir}/chatmode_todo_object_response.json", "w", encoding="utf-8") as f:
        json.dump(task_res, f, ensure_ascii=False, indent=4)

    return todo_json, task_res

async def generate_task_workflow(query: str):
    with open("system_prompts/task_generator.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()

    RESPONSE_SCHEMA = {
        "type": "object",
        "properties": {
            "title": {"type": "string"},
            "description": {"type": "string"},
            "todos": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "string"},
                        "text": {"type": "string"},
                        "status": {"type": "string", "enum": ["pending", "executing", "finished"]},
                        "agent": {"type": "string"},
                        "subTodos": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "text": {"type": "string"},
                                    "status": {"type": "string", "enum": ["pending", "executing", "finished"]}
                                },
                                "required": ["text", "status"]
                            }
                        }
                    },
                    "required": ["id", "text", "status", "agent", "subTodos"]
                }
            }
        },
        "required": ["title", "description", "todos"]
    }

    prompt = f"User request:\n{query}\n\nGenerate the task workflow JSON."

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT,
    )

    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
    )
    ## Generated todo
    todo_json = json.loads(resp.text)
    with open(f"{config.output_dir}/chatmode_todo_generated.json", "w", encoding="utf-8") as f:
        json.dump(todo_json, f, ensure_ascii=False, indent=4)


    ## Create todo object
    task_res = await canvas_ops.create_todo(todo_json)

    with open(f"{config.output_dir}/chatmode_todo_object_response.json", "w", encoding="utf-8") as f:
        json.dump(task_res, f, ensure_ascii=False, indent=4)

    start_background_agent_processing(todo_json, task_res)

    return task_res

async def generate_dili_diagnosis():
    with open("system_prompts/dili_diagnosis_prompt.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT_DILI = f.read()
    RESPONSE_SCHEMA = {
        "type": "OBJECT",
        "properties": {
            "title": {
                "type": "STRING",
                "description": "Section title, always 'DILI Diagnostic Panel'"
            },
            "component": {
                "type": "STRING",
                "description": "Component identifier, always 'DILIDiagnostic'"
            },
            "props": {
                "type": "OBJECT",
                "properties": {
                    "pattern": {
                        "type": "OBJECT",
                        "properties": {
                            "classification": {"type": "STRING"},
                            "R_ratio": {"type": "NUMBER"},
                            "keyLabs": {
                                "type": "ARRAY",
                                "items": {
                                    "type": "OBJECT",
                                    "properties": {
                                        "label": {"type": "STRING"},
                                        "value": {"type": "STRING"},
                                        "note": {"type": "STRING"}
                                    },
                                    "required": ["label", "value", "note"]
                                }
                            },
                            "clinicalFeatures": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            }
                        },
                        "required": ["classification", "R_ratio", "keyLabs", "clinicalFeatures"]
                    },
                    "causality": {
                        "type": "OBJECT",
                        "properties": {
                            "primaryDrug": {"type": "STRING"},
                            "contributingFactors": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "mechanisticRationale": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            }
                        },
                        "required": ["primaryDrug", "contributingFactors", "mechanisticRationale"]
                    },
                    "severity": {
                        "type": "OBJECT",
                        "properties": {
                            "features": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "prognosis": {"type": "STRING"}
                        },
                        "required": ["features", "prognosis"]
                    },
                    "management": {
                        "type": "OBJECT",
                        "properties": {
                            "immediateActions": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "consults": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },
                            "monitoringPlan": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            }
                        },
                        "required": ["immediateActions", "consults", "monitoringPlan"]
                    }
                },
                "required": ["pattern", "causality", "severity", "management"]
            }
        },
        "required": ["title", "component", "props"]
    }

    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT_DILI,
    )
    print(f"Running generate_dili_diagnosis model")
    ehr_data = await load_ehr()
    prompt = f"""Please generate DILI diagnosis object.


        This is patient raw data : {ehr_data}"""

    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
        )
    result = json.loads(resp.text)
    object_data = result.get("props",{})
    with open(f"{config.output_dir}/dili_diagnosis_object.json", "w", encoding="utf-8") as f:
        json.dump(object_data, f, ensure_ascii=False, indent=4)
    return object_data



async def generate_patient_report():
    with open("system_prompts/patient_report_prompt.md", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT_PATIENT = f.read()
    RESPONSE_SCHEMA = {
        "type": "OBJECT",
        "properties": {
            "title": {
                "type": "STRING",
                "description": "Always 'Patient Summary Report'"
            },
            "component": {
                "type": "STRING",
                "description": "Always 'PatientReport'"
            },
            "props": {
                "type": "OBJECT",
                "properties": {
                    "patientData": {
                        "type": "OBJECT",
                        "properties": {
                            "name": {"type": "STRING"},
                            "date_of_birth": {"type": "STRING"},
                            "age": {"type": "NUMBER"},
                            "sex": {"type": "STRING"},
                            "mrn": {"type": "STRING"},
                            "primaryDiagnosis": {"type": "STRING"},

                            "problem_list": {
                                "type": "ARRAY",
                                "items": {
                                    "type": "OBJECT",
                                    "properties": {
                                        "name": {"type": "STRING"},
                                        "status": {"type": "STRING"}
                                    },
                                    "required": ["name", "status"]
                                }
                            },

                            "allergies": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },

                            "medication_history": {
                                "type": "ARRAY",
                                "items": {
                                    "type": "OBJECT",
                                    "properties": {
                                        "name": {"type": "STRING"},
                                        "dose": {"type": "STRING"}
                                    },
                                    "required": ["name", "dose"]
                                }
                            },

                            "acute_event_summary": {"type": "STRING"},

                            "diagnosis_acute_event": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            },

                            "causality": {"type": "STRING"},

                            "management_recommendations": {
                                "type": "ARRAY",
                                "items": {"type": "STRING"}
                            }
                        },
                        "required": ['name', 'date_of_birth', 'age', 'sex', 'mrn', 'primaryDiagnosis', 'problem_list', 'allergies', 'medication_history', 'acute_event_summary', 'diagnosis_acute_event', 'causality', 'management_recommendations']
                    }
                },
                "required": ["patientData"]
            }
        },
        "required": ["title", "component", "props"]
    }
 
    model = genai.GenerativeModel(
        MODEL,
        system_instruction=SYSTEM_PROMPT_PATIENT,
    )
    print(f"Running generate_patient_report model")
    ehr_data = await load_ehr()
    prompt = f"""Please generate Patient Report object.


        This is patient raw data : {ehr_data}"""

    resp = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RESPONSE_SCHEMA
        }
        )
    result = json.loads(resp.text)
    object_data = result.get("props",{})

    with open(f"{config.output_dir}/patient_report_object.json", "w", encoding="utf-8") as f:
        json.dump(object_data, f, ensure_ascii=False, indent=4)
    return object_data

def create_diagnosis(payload):
    print("Start create object")
    url = BASE_URL + "/api/dili-diagnostic"
    payload['zone'] = "dili-analysis-zone"
    # payload['name'] = "dili-analysis-zone"
    with open(f"{config.output_dir}/diagnosis_create_payload.json", "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=4)
    response = requests.post(url, json=payload)
    print(response.status_code)
    with open(f"{config.output_dir}/diagnosis_create_response.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4) 

async def create_dili_diagnosis():
    print("Start generate DILI object")
    diagnosis_content = await generate_dili_diagnosis()

    print("Diagnosis content generated")

    # canvas_ops.create_diagnosis(diagnosis_content)
    create_diagnosis(diagnosis_content)

def create_report(payload):
    print("Start create object")
    url = BASE_URL + "/api/patient-report"
    # payload['zone'] = "dili-analysis-zone"
    payload['zone'] = "patient-report-zone"
    response = requests.post(url, json=payload)
    print(response.status_code)

async def create_patient_report():
    diagnosis_content = await generate_patient_report()

    print("Patient report content generated")

    create_report(diagnosis_content)

# start_time = time.time()

# # query = "Pull radiology data for Sarah Miller"
# # parse_tool(query)
# asyncio.run(generate_patient_report())
# end_time = time.time()
# execution_time = end_time - start_time
# print(f"Execution time: {execution_time:.4f} seconds")